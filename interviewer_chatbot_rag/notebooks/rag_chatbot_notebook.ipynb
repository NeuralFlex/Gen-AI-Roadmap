{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "911385cf-b4a2-407f-8283-935b23657f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from typing import TypedDict, List, Dict, Optional\n",
    "from langgraph.graph import StateGraph, END\n",
    "import google.generativeai as genai\n",
    "from tavily import TavilyClient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "9dacef1a-ede0-4853-948d-849708ce432d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "tavily_api_key = os.getenv(\"TAVILY_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "9e1b04d7-41eb-4391-82ab-ae663f301155",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not gemini_api_key:\n",
    "    raise ValueError(\"GEMINI_API_KEY not found in environment variables!\")\n",
    "genai.configure(api_key=gemini_api_key)\n",
    "\n",
    "if not tavily_api_key:\n",
    "    raise ValueError(\"TAVILY_API_KEY not found in environment variables!\")\n",
    "tavily = TavilyClient(api_key=tavily_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "2fc1627f-e132-423e-8f2b-b4cffba4b27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Helper Functions ----\n",
    "def call_gemini(prompt: str, retries=3, delay=5) -> str:\n",
    "    \"\"\"Call Gemini API with retry logic.\"\"\"\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            model = genai.GenerativeModel(\"gemini-2.5-flash\")  # Stable model\n",
    "            response = model.generate_content(prompt)\n",
    "            return response.text.strip() if response.text else \"\"\n",
    "        except Exception as e:\n",
    "            print(f\"Gemini API error (attempt {attempt+1}/{retries}): {e}\")\n",
    "            if attempt < retries - 1:\n",
    "                import time\n",
    "                time.sleep(delay)\n",
    "            else:\n",
    "                return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "ee3e111e-2dde-4cab-b9fc-5efb854003c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def search_tavily(query: str) -> list[str]:\n",
    "    \"\"\"Return up to 5 Tavily search result snippets as a list of strings.\"\"\"\n",
    "    try:\n",
    "        response = tavily.search(query=query[:370], top_k=5)\n",
    "        results = response.get(\"results\", [])\n",
    "        return [r.get(\"snippet\") or r.get(\"content\") or r.get(\"title\", \"\") for r in results][:5]\n",
    "    except Exception as e:\n",
    "        print(f\"Tavily search failed: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "046e06c6-1900-4770-9807-45ad61a57fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def safe_parse_json(response_text: str, fallback: Dict = None) -> Dict:\n",
    "    \"\"\"Safely parse JSON - optimized version.\"\"\"\n",
    "    if not response_text or not response_text.strip():\n",
    "        return fallback or {\"rating\": 0, \"feedback\": \"Empty response from API\"}\n",
    "    \n",
    "    # Try to extract JSON using regex (this is what's actually working)\n",
    "    match = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n",
    "    if match:\n",
    "        try:\n",
    "            return json.loads(match.group(0))\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "    \n",
    "    return fallback or {\"rating\": 0, \"feedback\": \"Failed to parse JSON response\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "16b3aaf5-5aae-4563-a34d-bf9ad80f8725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell separately first to upload CV\n",
    "def upload_cv_interactively():\n",
    "    \"\"\"Upload CV separately before starting the interview graph\"\"\"\n",
    "    print(\" Welcome to the AI Interviewer (Question Evaluation Mode)!\")\n",
    "    print(\"Please upload your CV/Resume\")\n",
    "    \n",
    "    # Create file upload widget for CV\n",
    "    file_upload = widgets.FileUpload(\n",
    "        accept='.pdf,.txt,.doc,.docx',\n",
    "        multiple=False,\n",
    "        description='Upload CV/Resume'\n",
    "    )\n",
    "    \n",
    "    upload_button = widgets.Button(description=\"Process CV\")\n",
    "    output = widgets.Output()\n",
    "    \n",
    "    cv_data = {}\n",
    "    \n",
    "    def on_upload_button_clicked(b):\n",
    "        with output:\n",
    "            output.clear_output()\n",
    "            if file_upload.value:\n",
    "                # Handle both tuple format (newer ipywidgets) and dict format (older)\n",
    "                if isinstance(file_upload.value, tuple):\n",
    "                    uploaded_file = file_upload.value[0]\n",
    "                else:\n",
    "                    uploaded_file = list(file_upload.value.values())[0]\n",
    "                \n",
    "                filename = uploaded_file['name']\n",
    "                content = uploaded_file['content']\n",
    "                \n",
    "                print(f\"üìÑ Processing CV: {filename}\")\n",
    "                \n",
    "                # Extract text from CV\n",
    "                cv_text = extract_text_from_cv(filename, content)\n",
    "                \n",
    "                if not cv_text.strip():\n",
    "                    print(\"‚ùå Could not extract text from the CV file\")\n",
    "                    return\n",
    "                \n",
    "                # Analyze CV to determine interview topic\n",
    "                topic = analyze_cv_for_topic(cv_text)\n",
    "                \n",
    "                print(f\"üéØ Detected interview focus: {topic}\")\n",
    "                \n",
    "                cv_data.update({\n",
    "                    \"cv_content\": cv_text,\n",
    "                    \"topic\": topic,\n",
    "                    \"cv_filename\": filename\n",
    "                })\n",
    "                \n",
    "                print(\"‚úÖ CV processed successfully!\")\n",
    "                print(\"üìù You can now run the interview with the processed CV data.\")\n",
    "                \n",
    "            else:\n",
    "                print(\"‚ùå Please upload a CV file first!\")\n",
    "    \n",
    "    # Display upload interface\n",
    "    upload_widget = widgets.VBox([\n",
    "        widgets.HBox([file_upload, upload_button]),\n",
    "        output\n",
    "    ])\n",
    "    display(upload_widget)\n",
    "    upload_button.on_click(on_upload_button_clicked)\n",
    "    \n",
    "    return cv_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "083b4b0d-f9ae-4992-b93f-750327f671ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class InterviewState(TypedDict):\n",
    "    topic: str\n",
    "    content: List[str]\n",
    "    questions: List[str]\n",
    "    answers: List[str]\n",
    "    feedback: List[Dict]\n",
    "    current_question: Optional[str]\n",
    "    current_answer: Optional[str]\n",
    "    step: int\n",
    "    max_questions: int\n",
    "    final_evaluation: Optional[Dict]\n",
    "    messages: List[Dict]\n",
    "    question_type: str\n",
    "    cv_content: str  # Add this\n",
    "    cv_filename: str  # Add this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "02bb217a-e646-4c8b-bc9f-4af98c4cf92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_and_process_cv():\n",
    "    \"\"\"Handle CV upload using file upload widget.\"\"\"\n",
    "    print(\" Welcome to the AI Interviewer (Question Evaluation Mode)!\")\n",
    "    print(\"Please upload your CV/Resume\")\n",
    "    \n",
    "    # Create file upload widget for CV\n",
    "    file_upload = widgets.FileUpload(\n",
    "        accept='.pdf,.txt,.doc,.docx',\n",
    "        multiple=False,\n",
    "        description='Upload CV/Resume'\n",
    "    )\n",
    "    \n",
    "    upload_button = widgets.Button(description=\"Process CV\")\n",
    "    output = widgets.Output()\n",
    "    \n",
    "    cv_data = {}\n",
    "    processing_complete = False\n",
    "    \n",
    "    def on_upload_button_clicked(b):\n",
    "        nonlocal processing_complete\n",
    "        with output:\n",
    "            output.clear_output()\n",
    "            if file_upload.value:\n",
    "                # Handle both tuple format (newer ipywidgets) and dict format (older)\n",
    "                if isinstance(file_upload.value, tuple):\n",
    "                    # Newer ipywidgets - value is a tuple of file info\n",
    "                    uploaded_file = file_upload.value[0]\n",
    "                    filename = uploaded_file['name']\n",
    "                    content = uploaded_file['content']\n",
    "                else:\n",
    "                    # Older ipywidgets - value is a dict\n",
    "                    uploaded_file = list(file_upload.value.values())[0]\n",
    "                    filename = uploaded_file['name']\n",
    "                    content = uploaded_file['content']\n",
    "                \n",
    "                print(f\"üìÑ Processing CV: {filename}\")\n",
    "                \n",
    "                # Extract text from CV\n",
    "                cv_text = extract_text_from_cv(filename, content)\n",
    "                \n",
    "                if not cv_text.strip():\n",
    "                    print(\"‚ùå Could not extract text from the CV file\")\n",
    "                    return\n",
    "                \n",
    "                # Analyze CV to determine interview topic\n",
    "                topic = analyze_cv_for_topic(cv_text)\n",
    "                \n",
    "                print(f\"üéØ Detected interview focus: {topic}\")\n",
    "                \n",
    "                cv_data.update({\n",
    "                    \"cv_content\": cv_text,\n",
    "                    \"topic\": topic,\n",
    "                    \"cv_filename\": filename\n",
    "                })\n",
    "                \n",
    "                print(\"‚úÖ CV processed successfully! Ready to start interview.\")\n",
    "                processing_complete = True\n",
    "            else:\n",
    "                print(\"‚ùå Please upload a CV file first!\")\n",
    "    \n",
    "    # Display upload interface\n",
    "    upload_widget = widgets.VBox([\n",
    "        widgets.HBox([file_upload, upload_button]),\n",
    "        output\n",
    "    ])\n",
    "    display(upload_widget)\n",
    "    upload_button.on_click(on_upload_button_clicked)\n",
    "    \n",
    "    # Wait for processing to complete\n",
    "    print(\"‚è≥ Waiting for CV upload...\")\n",
    "    while not processing_complete:\n",
    "        import time\n",
    "        time.sleep(1)\n",
    "    \n",
    "    return cv_data\n",
    "\n",
    "\n",
    "\n",
    "def extract_text_from_cv(filename: str, content: bytes) -> str:\n",
    "    \"\"\"Extract text from CV based on file type.\"\"\"\n",
    "    try:\n",
    "        if filename.endswith('.pdf'):\n",
    "            return extract_text_from_pdf(content)\n",
    "        elif filename.endswith('.txt'):\n",
    "            return content.decode('utf-8')\n",
    "        elif filename.endswith(('.doc', '.docx')):\n",
    "            return extract_text_from_doc(content, filename)\n",
    "        else:\n",
    "            # Fallback: try to decode as text\n",
    "            return content.decode('utf-8', errors='ignore')\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from CV: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def extract_text_from_pdf(content: bytes) -> str:\n",
    "    \"\"\"Extract text from PDF content.\"\"\"\n",
    "    try:\n",
    "        import PyPDF2\n",
    "        pdf_file = io.BytesIO(content)\n",
    "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "        text = \"\"\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "        return text\n",
    "    except ImportError:\n",
    "        print(\"PyPDF2 not available. Install with: pip install PyPDF2\")\n",
    "        return \"PDF text extraction requires PyPDF2\"\n",
    "    except Exception as e:\n",
    "        print(f\"PDF extraction error: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def extract_text_from_doc(content: bytes, filename: str) -> str:\n",
    "    \"\"\"Extract text from Word documents.\"\"\"\n",
    "    try:\n",
    "        if filename.endswith('.docx'):\n",
    "            from docx import Document\n",
    "            doc_file = io.BytesIO(content)\n",
    "            doc = Document(doc_file)\n",
    "            return \"\\n\".join([paragraph.text for paragraph in doc.paragraphs])\n",
    "        else:\n",
    "            # For .doc files, you might need antiword or other tools\n",
    "            return \"Word document extraction limited for .docx files\"\n",
    "    except ImportError:\n",
    "        print(\"python-docx not available. Install with: pip install python-docx\")\n",
    "        return \"DOCX extraction requires python-docx\"\n",
    "\n",
    "def analyze_cv_for_topic(cv_text: str) -> str:\n",
    "    \"\"\"Analyze CV content to determine interview focus.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Analyze this CV/resume and determine the most appropriate technical interview topic focus.\n",
    "    Consider skills, experience, technologies mentioned, and role preferences.\n",
    "    \n",
    "    CV Content:\n",
    "    {cv_text[:3000]}  # Limit length for API\n",
    "    \n",
    "    Return ONLY the main interview topic as a short phrase (e.g., \"Python backend development\", \"Data science with machine learning\", \"Frontend React development\", \"C++ systems programming\").\n",
    "    \"\"\"\n",
    "    \n",
    "    topic = call_gemini(prompt) or \"Software Development\"\n",
    "    return topic.strip()\n",
    "\n",
    "def generate_first_question_from_cv(cv_text: str, topic: str, question_type: str) -> str:\n",
    "    \"\"\"Generate first question based on CV content.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Based on the following CV and the interview topic '{topic}', generate an appropriate first interview question.\n",
    "    \n",
    "    CV Excerpt:\n",
    "    {cv_text[:2000]}\n",
    "    \n",
    "    Question Style: {'Broad, general question' if question_type.startswith('broad') else 'Specific, detailed question'}\n",
    "    \n",
    "    The question should be relevant to the candidate's background and the topic '{topic}'.\n",
    "    Return ONLY the question text.\n",
    "    \"\"\"\n",
    "    \n",
    "    question = call_gemini(prompt) or f\"Tell me about your experience with {topic}.\"\n",
    "    return question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "a509642b-a178-42c0-be08-2bbbcd7ed995",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def setup_node(state: InterviewState) -> InterviewState:\n",
    "    print(\" Welcome to the AI Interviewer (Question Evaluation Mode)!\")\n",
    "    \n",
    "    # CV content should already be in state\n",
    "    cv_content = state.get(\"cv_content\", \"\")\n",
    "    topic = state.get(\"topic\", \"\")\n",
    "    \n",
    "    if not cv_content:\n",
    "        raise ValueError(\"No CV content found. Please upload a CV first.\")\n",
    "    \n",
    "    print(f\"üéØ Interview focus: {topic}\")\n",
    "    print(\"Choose question style:\")\n",
    "    print(\"1. Broad, follow-up questions (general, builds on previous answers)\")\n",
    "    print(\"2. Narrow, follow-up questions (specific, probes details from previous answers)\")\n",
    "    print(\"3. Broad, non-follow-up questions (general, new topic aspects)\")\n",
    "    print(\"4. Narrow, non-follow-up questions (specific, new topic aspects)\")\n",
    "    choice = input(\"Enter choice (1-4): \").strip()\n",
    "    question_type_map = {\n",
    "        \"1\": \"broad_followup\",\n",
    "        \"2\": \"narrow_followup\",\n",
    "        \"3\": \"broad_nonfollowup\",\n",
    "        \"4\": \"narrow_nonfollowup\"\n",
    "    }\n",
    "    question_type = question_type_map.get(choice, \"broad_followup\")\n",
    "\n",
    "    content_list = search_tavily(f\"technical interview questions for {topic} role\")\n",
    "    initial_messages = [{\"role\": \"user\", \"content\": f\"CV-based interview for: {topic}\"}]\n",
    "\n",
    "    # Generate the first question based on CV\n",
    "    first_question = generate_first_question_from_cv(cv_content, topic, question_type)\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"content\": content_list,\n",
    "        \"messages\": initial_messages,\n",
    "        \"step\": 0,\n",
    "        \"questions\": [],\n",
    "        \"answers\": [],\n",
    "        \"feedback\": [],\n",
    "        \"current_question\": first_question,\n",
    "        \"question_type\": question_type\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "88d12a46-5c48-4a2f-8073-73db68b616ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_answer_node(state: InterviewState) -> InterviewState:\n",
    "    \"\"\"Get candidate answer\"\"\"\n",
    "    current_q = state.get(\"current_question\")\n",
    "    if not current_q:\n",
    "        raise ValueError(\"No current_question found in state.\")\n",
    "\n",
    "    print(f\"\\n‚ùì Generated Question {state['step'] + 1}: {current_q}\\n\")\n",
    "    answer = input(\"üí≠ Your answer: \").strip()\n",
    "\n",
    "    new_messages = state['messages'] + [\n",
    "        {\"role\": \"interviewer\", \"content\": current_q},\n",
    "        {\"role\": \"candidate\", \"content\": answer}\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"current_answer\": answer,\n",
    "        \"messages\": new_messages,\n",
    "        \"questions\": state['questions'] + [current_q],\n",
    "        \"answers\": state['answers'] + [answer]\n",
    "    }\n",
    "\n",
    "def evaluate_question_node(state: InterviewState) -> InterviewState:\n",
    "    \"\"\"Rate the quality of the last question and the candidate's answer.\"\"\"\n",
    "    # Compile transcript of previous Q&A and feedback\n",
    "    transcript = \"\"\n",
    "    for i in range(len(state['questions']) - 1):\n",
    "        q = state['questions'][i]\n",
    "        a = state['answers'][i]\n",
    "        f = state['feedback'][i] if i < len(state['feedback']) else {}\n",
    "        transcript += f\"Previous Q{i+1}: {q}\\nPrevious A{i+1}: {a}\\nPrevious Feedback: {f.get('question_feedback', {}).get('feedback', '')}\\n\\n\"\n",
    "\n",
    "    last_q = state['questions'][-1]\n",
    "    last_a = state['answers'][-1]\n",
    "    full_messages = json.dumps(state['messages'])\n",
    "    full_content = \"\\n\".join(state['content'])\n",
    "\n",
    "    # Question feedback prompt\n",
    "    question_prompt = f\"\"\"\n",
    "You are an expert interviewer. Evaluate the following question for its clarity, relevance, and ability to probe understanding, considering the ENTIRE interview history, accumulated context, all previous messages, questions, answers, and feedback.\n",
    "\n",
    "Full Interview History (Messages): {full_messages}\n",
    "Accumulated Context (Search Snippets): {full_content}\n",
    "Previous Q&A Transcript: {transcript}\n",
    "Current Question: {last_q}\n",
    "Current Candidate Answer: {last_a}\n",
    "\n",
    "Provide a rating (1-10) for question quality and 2-3 sentence feedback. Consider how well this question builds on prior answers, avoids repetition, incorporates context, and advances the topic.\n",
    "Return in JSON format:\n",
    "{{\n",
    "    \"rating\": 0,\n",
    "    \"feedback\": \"...\"\n",
    "}}\n",
    "\"\"\"\n",
    "    question_feedback_text = call_gemini(question_prompt)\n",
    "    question_feedback = safe_parse_json(question_feedback_text, {\"rating\": 0, \"feedback\": \"Failed to generate question feedback.\"})\n",
    "\n",
    "    # Answer feedback prompt\n",
    "    answer_prompt = f\"\"\"\n",
    "You are an expert interviewer. Evaluate the following candidate answer for its clarity, relevance, depth, and alignment with the question, considering the ENTIRE interview history and context.\n",
    "\n",
    "Full Interview History (Messages): {full_messages}\n",
    "Accumulated Context (Search Snippets): {full_content}\n",
    "Previous Q&A Transcript: {transcript}\n",
    "Current Question: {last_q}\n",
    "Current Candidate Answer: {last_a}\n",
    "\n",
    "Provide a rating (1-10) for answer quality and 2-3 sentence feedback. Highlight strengths and areas for improvement.\n",
    "Return in JSON format:\n",
    "{{\n",
    "    \"rating\": 0,\n",
    "    \"feedback\": \"...\"\n",
    "}}\n",
    "\"\"\"\n",
    "    answer_feedback_text = call_gemini(answer_prompt)\n",
    "    answer_feedback = safe_parse_json(answer_feedback_text, {\"rating\": 0, \"feedback\": \"Failed to generate answer feedback.\"})\n",
    "\n",
    "    feedback = {\n",
    "        \"question_feedback\": question_feedback,\n",
    "        \"answer_feedback\": answer_feedback\n",
    "    }\n",
    "    # print(f\"üí° Question Feedback: {question_feedback['feedback']} (Rating: {question_feedback['rating']})\")\n",
    "    # print(f\"üí° Answer Feedback: {answer_feedback['feedback']} (Rating: {answer_feedback['rating']})\")\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"feedback\": state['feedback'] + [feedback],\n",
    "        \"step\": state['step'] + 1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "c96de2de-2b39-4a23-8b64-675d77c33382",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_question_node(state: InterviewState) -> InterviewState:\n",
    "    \"\"\"Generate next question based on type (broad/narrow, follow-up/non-follow-up).\"\"\"\n",
    "    updated_content = state['content']\n",
    "    question_type = state['question_type']\n",
    "    is_followup = \"followup\" in question_type\n",
    "    is_broad = question_type.startswith(\"broad\")\n",
    "\n",
    "    if state['step'] > 0:\n",
    "        last_q = state['questions'][-1]\n",
    "        last_a = state['answers'][-1]\n",
    "        tavily_results = search_tavily(f\"{state['topic']} interview context: Q: {last_q} A: {last_a}\")\n",
    "        updated_content += tavily_results\n",
    "\n",
    "    prompt_instruction = \"\"\n",
    "    if is_followup:\n",
    "        prompt_instruction = f\"Generate a {'broad, general' if is_broad else 'specific, detailed'} follow-up question that directly probes details from the previous answer: {state['answers'][-1] if state['answers'] else ''}.\"\n",
    "    else:\n",
    "        prompt_instruction = f\"Generate a {'broad, general' if is_broad else 'specific, detailed'} question that explores a new aspect of the topic, independent of the previous answer.\"\n",
    "\n",
    "    prompt_question = f\"\"\"\n",
    "You are an expert interviewer. Using the following reference content:\n",
    "{updated_content}\n",
    "\n",
    "{prompt_instruction}\n",
    "Topic: {state['topic']}\n",
    "Question number: {state['step'] + 1}\n",
    "Return ONLY the question text.\n",
    "\"\"\"\n",
    "    question = call_gemini(prompt_question) or f\"Tell me more about {state['topic']}.\"\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"current_question\": question,\n",
    "        \"content\": updated_content\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "15028096-1604-4852-8ffa-9bb7068e47f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def final_evaluation_node(state: InterviewState) -> InterviewState:\n",
    "    \"\"\"Generate final evaluation of all questions.\"\"\"\n",
    "    print(\"\\nüìä Generating final evaluation of all questions...\")\n",
    "    transcript = \"\"\n",
    "    for i, (q, a, f) in enumerate(zip(state['questions'], state['answers'], state['feedback']), 1):\n",
    "        transcript += f\"Q{i}: {q}\\nA{i}: {a}\\nQuestion Feedback: {f['question_feedback']['feedback']} (Rating: {f['question_feedback']['rating']})\\nAnswer Feedback: {f['answer_feedback']['feedback']} (Rating: {f['answer_feedback']['rating']})\\n\\n\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Based on this transcript, produce a JSON summary evaluation of the questions:\n",
    "{transcript}\n",
    "\n",
    "JSON format ONLY:\n",
    "{{\n",
    "    \"overall_quality\": 0-10,\n",
    "    \"strengths\": [\"...\"],\n",
    "    \"areas_for_improvement\": [\"...\"],\n",
    "    \"recommendation\": \"keep/revise/remove\",\n",
    "    \"final_feedback\": \"...\"\n",
    "}}\n",
    "\"\"\"\n",
    "    response_text = call_gemini(prompt)\n",
    "    evaluation = safe_parse_json(response_text, {\"overall_quality\": 0, \"recommendation\": \"revise\", \"final_feedback\": \"Failed to generate evaluation.\"})\n",
    "\n",
    "    return {**state, \"final_evaluation\": evaluation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "d6a73f26-7992-4aad-8011-7a6fd76cdf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def display_results_node(state: InterviewState) -> InterviewState:\n",
    "#     \"\"\"Display final report\"\"\"\n",
    "#     print(\"\\n\" + \"=\"*60)\n",
    "#     print(\" INTERVIEW COMPLETE - FINAL REPORT\")\n",
    "#     print(\"=\"*60)\n",
    "#     print(f\"\\n Topic: {state['topic']}\")\n",
    "#     print(\"\\n Questions & Feedback:\")\n",
    "#     for i, (q, a, f) in enumerate(zip(state['questions'], state['answers'], state['feedback']), 1):\n",
    "#         print(f\"\\n{i}. {q}\")\n",
    "#         print(f\"    Answer: {a}\")\n",
    "#         print(f\"    Feedback: {f}\")\n",
    "\n",
    "#     print(\"\\nüìä Final Evaluation:\")\n",
    "#     eval_data = state['final_evaluation']\n",
    "#     if \"error\" in eval_data:\n",
    "#         print(\" Could not parse evaluation:\", eval_data[\"error\"])\n",
    "#     else:\n",
    "#         for k, v in eval_data.items():\n",
    "#             print(f\"   {k}: {v}\")\n",
    "\n",
    "#     with open(\"interview_results.json\", \"w\") as f:\n",
    "#         json.dump(state, f, indent=2)\n",
    "#     print(\"\\n Results saved to 'interview_results.json'\")\n",
    "#     return state\n",
    "\n",
    "\n",
    "def display_results_node(state: InterviewState) -> InterviewState:\n",
    "    \"\"\"Display final report\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üéØ INTERVIEW COMPLETE - FINAL REPORT\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nüìã Topic: {state['topic']}\")\n",
    "    print(f\"üìù Questions Completed: {len(state['questions'])}\")\n",
    "    \n",
    "    # Show minimal question summary first\n",
    "    print(f\"\\nüìã QUESTIONS SUMMARY:\")\n",
    "    for i, q in enumerate(state['questions'], 1):\n",
    "        print(f\"  {i}. {q[:80]}{'...' if len(q) > 80 else ''}\")\n",
    "    \n",
    "    # Now show all the detailed feedback\n",
    "    display_all_feedback(state)\n",
    "    \n",
    "    # Then show the final evaluation\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìà FINAL EVALUATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    eval_data = state['final_evaluation']\n",
    "    if \"error\" in eval_data:\n",
    "        print(\"‚ùå Could not parse evaluation:\", eval_data[\"error\"])\n",
    "    else:\n",
    "        print(f\"   Overall Quality: {eval_data.get('overall_quality', 'N/A')}/10\")\n",
    "        print(f\"   Recommendation: {eval_data.get('recommendation', 'N/A')}\")\n",
    "        print(f\"\\n   Strengths:\")\n",
    "        for strength in eval_data.get('strengths', []):\n",
    "            print(f\"     ‚Ä¢ {strength}\")\n",
    "        print(f\"\\n   Areas for Improvement:\")\n",
    "        for area in eval_data.get('areas_for_improvement', []):\n",
    "            print(f\"     ‚Ä¢ {area}\")\n",
    "        print(f\"\\n   Final Feedback: {eval_data.get('final_feedback', 'N/A')}\")\n",
    "\n",
    "    # Save results\n",
    "    with open(\"interview_results.json\", \"w\") as f:\n",
    "        json.dump(state, f, indent=2)\n",
    "    print(f\"\\nüíæ Results saved to 'interview_results.json'\")\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "1e5cdf26-cb05-4c4b-af1a-f133f46052f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_all_feedback(state: InterviewState):\n",
    "    \"\"\"Display all question and answer feedback at the end in a clean format.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìä DETAILED FEEDBACK SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for i, (q, a, f) in enumerate(zip(state['questions'], state['answers'], state['feedback']), 1):\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"QUESTION {i}: {q}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        print(f\"üí≠ YOUR ANSWER: {a}\")\n",
    "        print(f\"\\nüí° QUESTION FEEDBACK (Rating: {f['question_feedback']['rating']}/10):\")\n",
    "        print(f\"   {f['question_feedback']['feedback']}\")\n",
    "        print(f\"\\n‚úÖ ANSWER FEEDBACK (Rating: {f['answer_feedback']['rating']}/10):\")\n",
    "        print(f\"   {f['answer_feedback']['feedback']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "6d36f3ae-07e3-4908-b461-70424ef009a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_node(state: InterviewState) -> InterviewState:\n",
    "    \"\"\"Get candidate answer\"\"\"\n",
    "    current_q = state.get(\"current_question\")\n",
    "    if not current_q:\n",
    "        raise ValueError(\"No current_question found in state.\")\n",
    "\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"‚ùì QUESTION {state['step'] + 1}/{state['max_questions']}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"{current_q}\\n\")\n",
    "    \n",
    "    answer = input(\"üí≠ Your answer: \").strip()\n",
    "\n",
    "    new_messages = state['messages'] + [\n",
    "        {\"role\": \"interviewer\", \"content\": current_q},\n",
    "        {\"role\": \"candidate\", \"content\": answer}\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"current_answer\": answer,\n",
    "        \"messages\": new_messages,\n",
    "        \"questions\": state['questions'] + [current_q],\n",
    "        \"answers\": state['answers'] + [answer]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "90689ef5-486f-4e5c-a1b3-9c81efc39293",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Graph ----\n",
    "def should_continue(state: InterviewState) -> str:\n",
    "    return \"generate_question\" if state['step'] < state['max_questions'] else \"final_evaluation\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "01a3474e-369b-4eb6-9291-a89396601c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "builder = StateGraph(InterviewState)\n",
    "builder.add_node(\"setup\", setup_node)\n",
    "builder.add_node(\"get_answer\", get_answer_node)\n",
    "builder.add_node(\"evaluate_question\", evaluate_question_node)\n",
    "builder.add_node(\"generate_question\", generate_question_node)\n",
    "builder.add_node(\"final_evaluation\", final_evaluation_node)\n",
    "builder.add_node(\"display_results\", display_results_node)\n",
    "\n",
    "builder.set_entry_point(\"setup\")\n",
    "builder.add_edge(\"setup\", \"get_answer\")\n",
    "builder.add_edge(\"get_answer\", \"evaluate_question\")\n",
    "builder.add_conditional_edges(\n",
    "    \"evaluate_question\",\n",
    "    should_continue,\n",
    "    {\"generate_question\": \"generate_question\", \"final_evaluation\": \"final_evaluation\"}\n",
    ")\n",
    "builder.add_edge(\"generate_question\", \"get_answer\")\n",
    "builder.add_edge(\"final_evaluation\", \"display_results\")\n",
    "builder.add_edge(\"display_results\", END)\n",
    "\n",
    "interview_graph = builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "2043b87e-7c93-4f19-92a1-f411e53c5605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Welcome to the AI Interviewer (Question Evaluation Mode)!\n",
      "Please upload your CV/Resume\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "133c50550a4f4e40be44731551fedd36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(FileUpload(value=(), accept='.pdf,.txt,.doc,.docx', description='Upload CV/Resum‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell first to upload your CV\n",
    "cv_data = upload_cv_interactively()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b0f182-c556-47b2-b2a9-58772133c151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Welcome to the AI Interviewer (Question Evaluation Mode)!\n",
      "üéØ Interview focus: Mobile application development (React Native & Jetpack Compose)\n",
      "Choose question style:\n",
      "1. Broad, follow-up questions (general, builds on previous answers)\n",
      "2. Narrow, follow-up questions (specific, probes details from previous answers)\n",
      "3. Broad, non-follow-up questions (general, new topic aspects)\n",
      "4. Narrow, non-follow-up questions (specific, new topic aspects)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter choice (1-4):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "‚ùì QUESTION 1/3\n",
      "==================================================\n",
      "In your experience developing cross-platform mobile applications with React Native, and native Android applications with Jetpack Compose (such as the 'Smart Beauty' app), you've focused on UI/UX implementation, responsiveness, and performance optimization. Can you describe a specific instance where you had to significantly optimize the performance or smooth UI interactions of an application using either React Native or Jetpack Compose, detailing the problem you faced, the specific tools and techniques you employed, and the measurable impact of your solution?\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "üí≠ Your answer:  i cant say\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "‚ùì QUESTION 2/3\n",
      "==================================================\n",
      "Based on your understanding, what's the fundamental difference in the type of application development React Native enables compared to Jetpack Compose?\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "üí≠ Your answer:  React native uses js which then interacts with java or kotlin but jc directly deALS WITH JAVA AND KOTLINA\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---- Run ----\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "# Run this cell after uploading CV to start the interview\n",
    "    if cv_data and cv_data.get(\"cv_content\"):\n",
    "        initial_state = {\n",
    "            \"topic\": cv_data[\"topic\"],\n",
    "            \"content\": [],\n",
    "            \"questions\": [],\n",
    "            \"answers\": [],\n",
    "            \"feedback\": [],\n",
    "            \"current_question\": None,\n",
    "            \"current_answer\": None,\n",
    "            \"step\": 0,\n",
    "            \"max_questions\": 3,\n",
    "            \"final_evaluation\": None,\n",
    "            \"messages\": [],\n",
    "            \"question_type\": \"broad_followup\",\n",
    "            \"cv_content\": cv_data[\"cv_content\"],\n",
    "            \"cv_filename\": cv_data[\"cv_filename\"]\n",
    "        }\n",
    "        \n",
    "        final_state = interview_graph.invoke(initial_state)\n",
    "    else:\n",
    "        print(\"No CV data found. Please upload a CV first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83b3007-d71f-4dc4-9ae6-5b876dcbe1c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
